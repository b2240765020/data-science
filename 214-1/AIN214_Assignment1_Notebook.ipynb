{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JsD4n549KSW"
   },
   "source": [
    "# **AIN 214 - PA1 - FALL 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeu4gamv8uxb"
   },
   "source": [
    "**Student ID** : 2240765020\n",
    "\n",
    "**Name-Surname**   : Sude Gündüz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "so7UTKwA8ULy"
   },
   "source": [
    "**Deadline: 3.11.2025 (23:59:59)**\n",
    "\n",
    "**Submission:** Submit your Jupyter Notebooks via https://submit.cs.hacettepe.edu.tr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9crUPV39bKP"
   },
   "source": [
    "# **Necessary Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bDF8rpnv9kjd"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd \n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzjmuhYk90CY"
   },
   "source": [
    "# **Notes:**\n",
    "\n",
    "* Use pandas dataframe (df) to load the data.\n",
    "\n",
    "* Use numpy or pandas operations for the requested tasks unless otherwise specified.\n",
    "\n",
    "* You can insert more cells if it is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErBKcN6KBvW8"
   },
   "source": [
    "# **PART 1: Flight Delays and Cancellations Dataset**\n",
    "\n",
    "The US Department of Transportation's Bureau of Transportation.\n",
    "\n",
    "**Dataset Path: \"datasets/flights_dataset/*.csv\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdgQNea5raAd"
   },
   "source": [
    "- `flights.csv` contains the flight information\n",
    "\n",
    "| Variable   | Description                                          |\n",
    "|------------|------------------------------------------------------|\n",
    "| `year`, `month`, `day` | The time information of the flight |\n",
    "| `dep_time`   | Departure time (in the format hhmm) where`NA` corresponds to a cancelled flight        |\n",
    "| `sched_dep_time`    | Scheduled departure time                        |\n",
    "| `dep_delay`  | Departure delay, in minutes (negative for early)    |\n",
    "| `arr_time`  | Arrival time    |\n",
    "| `sched_arr_time`  | Scheduled arrival time    |\n",
    "| `arr_delay`  | Arrival delay, in minutes (negative for early)    |\n",
    "| `carrier`  | Carrier/airline code    |\n",
    "| `tailnum`  | Tail number of the plane    |\n",
    "| `origin`     | Origin airport where flight starts (IATA code)\n",
    "| `airline`    | Carrier/airline name                        |\n",
    "| `dest`       | Destination airport where flight lands (IATA code)  |\n",
    "| `air_time`    | The duration of flight (on air)                       |\n",
    "| `distance`    | The distance between origin and destination airports (miles)                        |\n",
    "| `hour`, `minute`, `time_hour`    | Time information of the flight                       \n",
    "\n",
    "- `flights_weather.csv` contains the same flight information as well as weather conditions such as\n",
    "\n",
    "| Variable   | Description                                           |\n",
    "|------------|-------------------------------------------------------|\n",
    "| `visib`      | Visibility (in miles)                                 |\n",
    "| `wind_gust`  | Wind gust speed (in mph)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EYHKHQRn_dE"
   },
   "source": [
    "### Load & Inspect the Data (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6np-3NMyjOCp"
   },
   "source": [
    "Load `flights.csv` as `flights_df` and `flights_weather.csv` as `weather_df` by using pandas DataFrame. (2 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pmawWZa2l21n"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "flights_df = pd.read_csv(\"datasets/flights_dataset/flights.csv\") \n",
    "weather_df = pd.read_csv(\"datasets/flights_dataset/flights_weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TppuOy1gl56u"
   },
   "source": [
    "Show the first and the last five rows of the datasets. (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CcIKAgghmEbW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
      "0  2022      1    1       1.0            2359        2.0     604.0   \n",
      "1  2022      1    1       1.0            2250       71.0     242.0   \n",
      "2  2022      1    1      10.0            2355       15.0     759.0   \n",
      "3  2022      1    1      25.0            2350       35.0     606.0   \n",
      "4  2022      1    1      35.0            2349       46.0     616.0   \n",
      "\n",
      "   sched_arr_time  arr_delay carrier  flight tailnum origin dest  air_time  \\\n",
      "0             618      -14.0      UA     555  N405UA    SEA  IAH     221.0   \n",
      "1             142       60.0      AS      72  N265AK    SEA  FAI     193.0   \n",
      "2             730       29.0      AS     270  N274AK    SEA  ATL     261.0   \n",
      "3             550       16.0      AS       7  N281AK    SEA  ORD     193.0   \n",
      "4             545       31.0      UA     507  N426UA    PDX  ORD     196.0   \n",
      "\n",
      "   distance  hour  minute             time_hour                airline  \n",
      "0      1874    23      59  2022-01-01T23:00:00Z  United Air Lines Inc.  \n",
      "1      1533    22      50  2022-01-01T22:00:00Z   Alaska Airlines Inc.  \n",
      "2      2182    23      55  2022-01-01T23:00:00Z   Alaska Airlines Inc.  \n",
      "3      1721    23      50  2022-01-01T23:00:00Z   Alaska Airlines Inc.  \n",
      "4      1739    23      49  2022-01-01T23:00:00Z  United Air Lines Inc.  \n",
      "        year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
      "111371  2022      6   30       NaN            1155        NaN       NaN   \n",
      "111372  2022      6   30       NaN            1448        NaN       NaN   \n",
      "111373  2022      6   30       NaN            1751        NaN       NaN   \n",
      "111374  2022      6   30       NaN            1145        NaN       NaN   \n",
      "111375  2022      6   30       NaN             720        NaN       NaN   \n",
      "\n",
      "        sched_arr_time  arr_delay carrier  flight tailnum origin dest  \\\n",
      "111371            2033        NaN      UA     206     NaN    SEA  EWR   \n",
      "111372            1732        NaN      DL     323   N3759    SEA  LAX   \n",
      "111373            2352        NaN      DL     377  N898DN    SEA  ORD   \n",
      "111374            2029        NaN      DL     114  N876DN    SEA  JFK   \n",
      "111375            1544        NaN      DL     168  N814DN    SEA  BOS   \n",
      "\n",
      "        air_time  distance  hour  minute             time_hour  \\\n",
      "111371       NaN      2402    11      55  2022-06-30T11:00:00Z   \n",
      "111372       NaN       954    14      48  2022-06-30T14:00:00Z   \n",
      "111373       NaN      1721    17      51  2022-06-30T17:00:00Z   \n",
      "111374       NaN      2422    11      45  2022-06-30T11:00:00Z   \n",
      "111375       NaN      2496     7      20  2022-06-30T07:00:00Z   \n",
      "\n",
      "                      airline  \n",
      "111371  United Air Lines Inc.  \n",
      "111372   Delta Air Lines Inc.  \n",
      "111373   Delta Air Lines Inc.  \n",
      "111374   Delta Air Lines Inc.  \n",
      "111375   Delta Air Lines Inc.  \n"
     ]
    }
   ],
   "source": [
    "# flights_df\n",
    "print(flights_df.head())\n",
    "print(flights_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cCNvWBN7mEpc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
      "0  2022      1    1       1.0            2359        2.0     604.0   \n",
      "1  2022      1    1       1.0            2250       71.0     242.0   \n",
      "2  2022      1    1      10.0            2355       15.0     759.0   \n",
      "3  2022      1    1      25.0            2350       35.0     606.0   \n",
      "4  2022      1    1      35.0            2349       46.0     616.0   \n",
      "\n",
      "   sched_arr_time  arr_delay carrier  ...    route  temp  dewp  humid  \\\n",
      "0             618      -14.0      UA  ...  SEA-IAH  33.0  23.0  66.06   \n",
      "1             142       60.0      AS  ...  SEA-FAI  32.0  23.0  69.04   \n",
      "2             730       29.0      AS  ...  SEA-ATL  33.0  23.0  66.06   \n",
      "3             550       16.0      AS  ...  SEA-ORD  33.0  23.0  66.06   \n",
      "4             545       31.0      UA  ...  PDX-ORD  33.0  19.0  55.75   \n",
      "\n",
      "   wind_dir  wind_speed  wind_gust  precip pressure visib  \n",
      "0     160.0     8.05546   9.270062     0.0   1022.9  10.0  \n",
      "1     170.0     9.20624  10.594357     0.0   1023.4  10.0  \n",
      "2     160.0     8.05546   9.270062     0.0   1022.9  10.0  \n",
      "3     160.0     8.05546   9.270062     0.0   1022.9  10.0  \n",
      "4     120.0     6.90468   7.945768     0.0   1025.1  10.0  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "        year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
      "111001  2022      6   30       NaN            1155        NaN       NaN   \n",
      "111002  2022      6   30       NaN            1448        NaN       NaN   \n",
      "111003  2022      6   30       NaN            1751        NaN       NaN   \n",
      "111004  2022      6   30       NaN            1145        NaN       NaN   \n",
      "111005  2022      6   30       NaN             720        NaN       NaN   \n",
      "\n",
      "        sched_arr_time  arr_delay carrier  ...    route  temp  dewp  humid  \\\n",
      "111001            2033        NaN      UA  ...  SEA-EWR  56.0  51.0  83.88   \n",
      "111002            1732        NaN      DL  ...  SEA-LAX  60.0  53.0  77.65   \n",
      "111003            2352        NaN      DL  ...  SEA-ORD  65.0  53.0  65.56   \n",
      "111004            2029        NaN      DL  ...  SEA-JFK  56.0  51.0  83.88   \n",
      "111005            1544        NaN      DL  ...  SEA-BOS  56.0  50.0  80.52   \n",
      "\n",
      "        wind_dir  wind_speed  wind_gust  precip pressure visib  \n",
      "111001      30.0     9.20624  10.594357     0.0   1021.5  10.0  \n",
      "111002      20.0     6.90468   7.945768     0.0   1021.9  10.0  \n",
      "111003     280.0     6.90468   7.945768     0.0   1021.3  10.0  \n",
      "111004      30.0     9.20624  10.594357     0.0   1021.5  10.0  \n",
      "111005     350.0     5.75390   6.621473     0.0   1021.8  10.0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# weather\n",
    "print(weather_df.head())\n",
    "print(weather_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uORkqzdbmKiv"
   },
   "source": [
    "How many records(rows) exists on each dataset? Use print function for the answer. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "W1V1oCdNmXk7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111376\n",
      "111006\n"
     ]
    }
   ],
   "source": [
    "# Show the number of records (rows) in each dataset.\n",
    "print(len(flights_df))\n",
    "print(len(weather_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccY3m3lIm2g8"
   },
   "source": [
    "What are the column types? Print columns and their datatypes. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_aSVJKcZnAhw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                int64\n",
      "month               int64\n",
      "day                 int64\n",
      "dep_time          float64\n",
      "sched_dep_time      int64\n",
      "dep_delay         float64\n",
      "arr_time          float64\n",
      "sched_arr_time      int64\n",
      "arr_delay         float64\n",
      "carrier            object\n",
      "flight              int64\n",
      "tailnum            object\n",
      "origin             object\n",
      "dest               object\n",
      "air_time          float64\n",
      "distance            int64\n",
      "hour                int64\n",
      "minute              int64\n",
      "time_hour          object\n",
      "airline            object\n",
      "dtype: object\n",
      "year                int64\n",
      "month               int64\n",
      "day                 int64\n",
      "dep_time          float64\n",
      "sched_dep_time      int64\n",
      "dep_delay         float64\n",
      "arr_time          float64\n",
      "sched_arr_time      int64\n",
      "arr_delay         float64\n",
      "carrier            object\n",
      "flight              int64\n",
      "tailnum            object\n",
      "origin             object\n",
      "dest               object\n",
      "air_time          float64\n",
      "distance            int64\n",
      "hour                int64\n",
      "minute              int64\n",
      "airline            object\n",
      "route              object\n",
      "temp              float64\n",
      "dewp              float64\n",
      "humid             float64\n",
      "wind_dir          float64\n",
      "wind_speed        float64\n",
      "wind_gust         float64\n",
      "precip            float64\n",
      "pressure          float64\n",
      "visib             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Show the data types for columns\n",
    "print(flights_df.dtypes)\n",
    "print(weather_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPPeSjV7mdt8"
   },
   "source": [
    "Compute a missing value summary (count and %) per column for each dataset. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cZb073HimuL9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                 0\n",
      "month                0\n",
      "day                  0\n",
      "dep_time          2445\n",
      "sched_dep_time       0\n",
      "dep_delay         2445\n",
      "arr_time          2542\n",
      "sched_arr_time       0\n",
      "arr_delay         2679\n",
      "carrier              0\n",
      "flight               0\n",
      "tailnum            129\n",
      "origin               0\n",
      "dest                 0\n",
      "air_time          2679\n",
      "distance             0\n",
      "hour                 0\n",
      "minute               0\n",
      "time_hour            0\n",
      "airline              0\n",
      "dtype: int64 year              0.000000\n",
      "month             0.000000\n",
      "day               0.000000\n",
      "dep_time          2.195266\n",
      "sched_dep_time    0.000000\n",
      "dep_delay         2.195266\n",
      "arr_time          2.282359\n",
      "sched_arr_time    0.000000\n",
      "arr_delay         2.405366\n",
      "carrier           0.000000\n",
      "flight            0.000000\n",
      "tailnum           0.115824\n",
      "origin            0.000000\n",
      "dest              0.000000\n",
      "air_time          2.405366\n",
      "distance          0.000000\n",
      "hour              0.000000\n",
      "minute            0.000000\n",
      "time_hour         0.000000\n",
      "airline           0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the summary\n",
    "nan_count = flights_df.isna().sum()\n",
    "total_values = flights_df.shape[0]\n",
    "nan_percentage = (nan_count/total_values)*100\n",
    "print(nan_count,nan_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juLxl7Iv0ONj"
   },
   "source": [
    "Identify likely key columns for a potential merging between two datasets. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Y6na0EQw0WHS"
   },
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# For a potential merging using year, month and day columns for the exact date along with the flight column would be a good choice.\n",
    "# Because these columns are unique for each flight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV_EhjXev6xM"
   },
   "source": [
    "### Data Exploration and Analysis (35 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G97mdVU-20AZ"
   },
   "source": [
    "**Note:** You can create new columns, merge datasets or perform any other operations in this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb4aFthhwIP8"
   },
   "source": [
    "How many different airlines has flight records in the flights dataset? (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LsgxqBP8v-Jm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "print(flights_df[\"airline\"].value_counts().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2VZ_8w1wcUl"
   },
   "source": [
    "Calculate the mean, min, max and std of the departure delay times. (Column: `dep_delay`) (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CB8wUFXAxBvr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  8.036674592173027\n",
      "min:  -36.0\n",
      "max:  2120.0\n",
      "std:  41.65103180286552\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "print(\"mean: \", flights_df[\"dep_delay\"].mean())\n",
    "print(\"min: \", flights_df[\"dep_delay\"].min())\n",
    "print(\"max: \", flights_df[\"dep_delay\"].max())\n",
    "print(\"std: \", flights_df[\"dep_delay\"].std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6aZ5m-xxCWb"
   },
   "source": [
    "Compute the summary statistics for weather columns. (`temperature`, `wind_speed`, `precipitation`) (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "R-YJEIM80wn6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    111006.000000\n",
      "mean         48.155538\n",
      "std           9.363201\n",
      "min          21.900000\n",
      "25%          42.000000\n",
      "50%          47.000000\n",
      "75%          54.000000\n",
      "max          99.000000\n",
      "Name: temp, dtype: float64\n",
      "count    110727.000000\n",
      "mean          6.995307\n",
      "std           4.507431\n",
      "min           0.000000\n",
      "25%           4.603120\n",
      "50%           6.904680\n",
      "75%           9.206240\n",
      "max          27.618720\n",
      "Name: wind_speed, dtype: float64\n",
      "count    111006.000000\n",
      "mean          0.005774\n",
      "std           0.022099\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max           0.320000\n",
      "Name: precip, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "print(weather_df[\"temp\"].describe())\n",
    "print(weather_df[\"wind_speed\"].describe())\n",
    "print(weather_df[\"precip\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr015Lpa0xF0"
   },
   "source": [
    "How many flights are delayed more than 15 minutes? Report count and the percentage. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "djddId1m2yPo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:  17539\n",
      "percentage: 15.74755782215199\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "count = (flights_df[\"dep_delay\"]>15).sum()\n",
    "print(\"count: \",count)\n",
    "total_count = flights_df[\"dep_delay\"].count()\n",
    "percentage = (count/total_values)*100\n",
    "print(\"percentage:\", percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tf7EL112y4N"
   },
   "source": [
    "How many flights are cancelled in the dataset? (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nqHPds9Q3JB7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2445\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "print(flights_df[\"dep_time\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkSTYCxT3IVt"
   },
   "source": [
    "Report top 5 airlines has the most cancellation by count and percantage seperately. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ywsU-3xR3XkY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline\n",
      "Alaska Airlines Inc.      1300\n",
      "Delta Air Lines Inc.       383\n",
      "Horizon Air                238\n",
      "SkyWest Airlines Inc.      165\n",
      "Southwest Airlines Co.     100\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "\n",
    "cancelled_flights = flights_df[flights_df[\"dep_time\"].isna()]\n",
    "cancelled_by_airline = cancelled_flights.groupby(\"airline\").size()\n",
    "sorted_flights=cancelled_by_airline.sort_values(ascending=False)\n",
    "print(sorted_flights.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VTkFMUFp3XVz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline\n",
      "Allegiant Air             6.122449\n",
      "JetBlue Airways           4.881657\n",
      "Spirit Air Lines          4.513889\n",
      "Alaska Airlines Inc.      3.108932\n",
      "Frontier Airlines Inc.    2.631579\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "total_flights = flights_df.groupby(\"airline\").size()\n",
    "percentage = (cancelled_by_airline/total_flights)*100\n",
    "sorted_percentage = percentage.sort_values(ascending=False)\n",
    "print(sorted_percentage.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEgm1g9K3fxJ"
   },
   "source": [
    "Which airline has the highest departure delay average? And what is the average delay for the airline? (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FxLH9CSa3quw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline:  JetBlue Airways\n",
      "avearge delay:  42.14152410575428\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "grouped_by_airline = flights_df.groupby(\"airline\")[\"dep_delay\"].mean()\n",
    "max_airline = grouped_by_airline.idxmax()\n",
    "max_avg_delay = grouped_by_airline.max()\n",
    "print(\"airline: \",max_airline)\n",
    "print(\"avearge delay: \",max_avg_delay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX7IWTLK3rQT"
   },
   "source": [
    "Which routes has the most cancelled flights? Report top 10 routes and the number of cancelled flights. (Note: A route is \"[origin]-[dest]\". For example PDX-BUR) (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "q7u7AUf-4JYS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route\n",
      "SEA-LAX    93\n",
      "SEA-ANC    78\n",
      "SEA-LAS    73\n",
      "SEA-SFO    73\n",
      "SEA-PDX    71\n",
      "SEA-JFK    70\n",
      "PDX-SEA    68\n",
      "SEA-DEN    66\n",
      "SEA-ORD    63\n",
      "SEA-PHX    60\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "cancelled_flights = weather_df[weather_df[\"dep_time\"].isna()]\n",
    "cancelled_by_route = cancelled_flights.groupby(\"route\").size()\n",
    "sorted_flights=cancelled_by_route.sort_values(ascending=False)\n",
    "print(sorted_flights.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdsRWPsT4P0k"
   },
   "source": [
    "Which route has the highest average departure delay time? Report top 10 routes with the average departure delay times. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DhBm5Ong4dkY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route with the highest average departure delay time:  PDX-DSM\n",
      "route\n",
      "PDX-DSM    35.782609\n",
      "PDX-GRR    35.739130\n",
      "SEA-MIA    29.916667\n",
      "PDX-FLL    28.043478\n",
      "SEA-CLT    27.313199\n",
      "PDX-STL    27.000000\n",
      "PDX-BOS    25.015748\n",
      "PDX-DFW    24.888889\n",
      "PDX-DAL    24.100000\n",
      "PDX-JFK    21.957565\n",
      "Name: dep_delay, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "grouped_by_route = weather_df.groupby(\"route\")[\"dep_delay\"].mean()\n",
    "max_route = grouped_by_route.idxmax()\n",
    "print(\"route with the highest average departure delay time: \",max_route)\n",
    "sorted_flights=grouped_by_route.sort_values(ascending=False)\n",
    "print(sorted_flights.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rZ-cM1j4nLv"
   },
   "source": [
    "Compare mean departure delay between rainy and non-rainy flights. (5 pts)\n",
    "\n",
    "Tip: Check `precip` column in weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8RUXliFb45fV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_rainy\n",
      "False     7.424000\n",
      "True     10.030635\n",
      "Name: dep_delay, dtype: float64\n",
      "Flights are more delayed on rainy days.\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "weather_df[\"is_rainy\"] = weather_df[\"precip\"]>0\n",
    "rainy_flights = weather_df.groupby(\"is_rainy\")[\"dep_delay\"].mean()\n",
    "print(rainy_flights)\n",
    "if rainy_flights[True]>rainy_flights[False]:\n",
    "    print(\"Flights are more delayed on rainy days.\")\n",
    "else:\n",
    "    print(\"Flights are more delayed on non-rainy days.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDh0LxIL5Bfe"
   },
   "source": [
    "Compare mean departure delay between wind condition. Consider 10 mile per hour or more wind gust is considered as windy. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "EvFyQgj56JZh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_windy\n",
      "False    7.514552\n",
      "True     9.216318\n",
      "Name: dep_delay, dtype: float64\n",
      "Flights are more delayed on windy days.\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "weather_df[\"is_windy\"] = weather_df[\"wind_gust\"]>=10\n",
    "windy_flights = weather_df.groupby(\"is_windy\")[\"dep_delay\"].mean()\n",
    "print(windy_flights)\n",
    "if windy_flights[True]>windy_flights[False]:\n",
    "    print(\"Flights are more delayed on windy days.\")\n",
    "else:\n",
    "    print(\"Flights are more delayed on non-windy days.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3suDJgQZm01"
   },
   "source": [
    "# **PART- 2**\n",
    "\n",
    "**SQL Questions**\n",
    "\n",
    "**You must use sqlite3 library for SQL operations**\n",
    "\n",
    "**Dataset Url: https://www.kaggle.com/datasets/ayeshaimran123/foodpanda-order-and-delivery-trends**\n",
    "\n",
    "\n",
    "The Foodpanda Order & Delivery Trends dataset contains information about customer orders made through the Foodpanda application. It includes details such as customer information, order status, restaurant data, ratings, payment methods, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOZouTkQh-aa"
   },
   "source": [
    "Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8g3KN0RagrO4"
   },
   "source": [
    "# Tables\n",
    "\n",
    "## 1. Customer Table\n",
    "\n",
    "| Column          | Type    | Key         | Description                                                                                              |\n",
    "|-----------------|---------|-------------|----------------------------------------------------------------------------------------------------------|\n",
    "| customer_id     | TEXT    | PRIMARY KEY | Unique identifier for each customer                                                                      |\n",
    "| gender          | TEXT    |             | Gender of the customer                                                                                   |\n",
    "| age_group       | TEXT    |             | Categorizes customers into broad age-based segments                                                      |\n",
    "| city            | TEXT    |             | Indicates the city where customer resides                                                                |\n",
    "| signup_date     | TEXT    |             | Represents the date when the customers created their account on Foodpanda platform                       |\n",
    "| order_frequency | INTEGER |             | nIdicates how frequently customer places orders                                                          |\n",
    "| last_order_date | TEXT    |             | Date of last order                                                                                       |\n",
    "| loyalty_points  | INTEGER |             | Represents the reward points earned by a customer                                                        |\n",
    "| churned         | TEXT    |             | nIdicates whether customer has stopped using the Foodpanda platform after a certain period of inactivity |\n",
    "\n",
    "\n",
    "\n",
    "## 2. Order Table\n",
    "\n",
    "| Column          | Type    | Key     | Description                                                                                                                                                |\n",
    "| --------------- | ------- | ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| order_id        | TEXT    | PRIMARY | Unique identifier for orders                                                                                                                               |\n",
    "| customer_id     | TEXT    | FOREIGN | Unique identifier for customers                                                                                                                            |\n",
    "| restaurant_id   | INTEGER | FOREIGN | Unique identifier for restaurants                                                                                                                          |\n",
    "| order_date      | TEXT    |         | Date of order                                                                                                                                              |\n",
    "| dish_name       | TEXT    |         | Indicates the type of the food item ordered by the customer                                                                                                |\n",
    "| category        | TEXT    |         | Represents the cusine of the ordered dish                                                                                                                  |\n",
    "| quantity        | INTEGER |         | Indicates the number of units of a particular dish ordered by the customer in a single order                                                               |\n",
    "| price           | REAL    |         | Represents the total cost of the ordered dish                                                                                                              |\n",
    "| payment_method  | TEXT    |         | Specifies the method used by the customer to pay for the order                                                                                             |\n",
    "| rating          | INTEGER |         | Indicates the numerical rating (usually on a scale such as 1–5) given by the customer to evaluate their satisfaction with the order or delivery experience |\n",
    "| rating_date     | TEXT    |         | Represents the date when the customer submitted their rating or review for the order                                                                       |\n",
    "| delivery_status | TEXT    |         | Describes the final status of the order’s delivery process                                                                                                 |\n",
    "\n",
    "\n",
    "## 3. Restaurant Table\n",
    "\n",
    "| Column          | Type    | Key     | Description                        |\n",
    "|-----------------|---------|---------|------------------------------------|\n",
    "| restaurant_id   | INTEGER | PRIMARY | Unique indetifiers for restaurants |\n",
    "| restaurant_name | TEXT    |         | Name of the restaurant             |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWvMCCPLi2W0"
   },
   "source": [
    "**Dataset path: Data/Foodpanda Analysis Dataset.csv**\n",
    "\n",
    "In this section, you will work with the Foodpanda Order & Delivery Trends dataset, which stores information about orders made on the Foodpanda platform. You are required to read the dataset from a CSV file, build a relational database, and write code to answer the following questions. When creating the database, you must follow the table schema described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lw6VazWW_jex"
   },
   "source": [
    "# Questions (50p)\n",
    "\n",
    "1. Read the csv file and create database. (10p)\n",
    "2. Find the top 3 restaurants with the highest total revenue. (revenue = quantity x price) (5p)\n",
    "3. Calculate the total quantity of dishes sold by category for each restaurant. (5p)\n",
    "4. List the top 5 customer with highest total spending (also show total spending value) (5p)\n",
    "5. Find the average rating for each restaurant. (5p)\n",
    "6. Check for duplicate orders (same customer_id+restaurant_id+order_date). (5p)\n",
    "7. Find the percentage of orders by delivery status. (7p)\n",
    "8. Analyze whether specific cities contribute a significantly larger portion to the total revenue compared to others. (8p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MUWbll4RluQg"
   },
   "outputs": [],
   "source": [
    "#1\n",
    "df = pd.read_csv(\"Data/Foodpanda Analysis Dataset.csv\")\n",
    "conn = sqlite3.connect(\"all.db\")\n",
    "conn.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.executescript(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Customers(\n",
    "    customer_id TEXT,\n",
    "    gender TEXT,\n",
    "    age_group TEXT,\n",
    "    city TEXT,\n",
    "    signup_date TEXT,\n",
    "    order_frequency INTEGER,\n",
    "    last_order_date TEXT,\n",
    "    loyalty_points INTEGER,\n",
    "    churned TEXT,\n",
    "    PRIMARY KEY(customer_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS Restaurants(\n",
    "    restaurant_id INTEGER,\n",
    "    restaurant_name TEXT,\n",
    "    PRIMARY KEY(restaurant_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS Orders(\n",
    "    order_id TEXT,\n",
    "    customer_id TEXT,\n",
    "    restaurant_id INTEGER,\n",
    "    order_date TEXT,\n",
    "    dish_name TEXT,\n",
    "    category TEXT,\n",
    "    quantity INTEGER,\n",
    "    price REAL,\n",
    "    payment_method TEXT,\n",
    "    rating INTEGER,\n",
    "    rating_date TEXT,\n",
    "    delivery_status TEXT,\n",
    "    PRIMARY KEY(order_id),\n",
    "    FOREIGN KEY (customer_id) REFERENCES Customer(customer_id),\n",
    "    FOREIGN KEY (restaurant_id) REFERENCES Restaurant(restaurant_id)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "restaurant_names = df[\"restaurant_name\"].drop_duplicates().tolist()\n",
    "restaurants={}\n",
    "i=1\n",
    "for name in restaurant_names:\n",
    "    restaurants[name]=i\n",
    "    i+=1\n",
    "df[\"restaurant_id\"] = df[\"restaurant_name\"].map(restaurants)\n",
    "\n",
    "customer_table=list(df[[\"customer_id\", \"gender\", \"age\", \"city\", \"signup_date\",\n",
    "    \"order_frequency\", \"last_order_date\", \"loyalty_points\", \"churned\"]].itertuples(index=False, name=None))\n",
    "\n",
    "cur.executemany(\"\"\"\n",
    "INSERT OR IGNORE INTO Customers (\n",
    "    customer_id, gender, age_group, city, signup_date,\n",
    "    order_frequency, last_order_date, loyalty_points, churned\n",
    ") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\", customer_table)\n",
    "\n",
    "restaurant_table = list(df[[\"restaurant_id\", \"restaurant_name\"]].itertuples(index=False, name=None))\n",
    "\n",
    "cur.executemany(\"\"\"\n",
    "INSERT OR IGNORE INTO Restaurants (restaurant_id, restaurant_name) VALUES (?, ?)\n",
    "\"\"\", restaurant_table)\n",
    "\n",
    "order_table = list(df[[\n",
    "    \"order_id\", \"customer_id\", \"restaurant_id\", \"order_date\", \n",
    "    \"dish_name\", \"category\", \"quantity\", \"price\", \n",
    "    \"payment_method\", \"rating\", \"rating_date\", \"delivery_status\"\n",
    "]].itertuples(index=False, name=None))\n",
    "\n",
    "cur.executemany(\"\"\"\n",
    "INSERT OR IGNORE INTO Orders (\n",
    "    order_id, customer_id, restaurant_id, order_date, \n",
    "    dish_name, category, quantity, price, \n",
    "    payment_method, rating, rating_date, delivery_status\n",
    ") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\", order_table)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uy8mEErq_jex"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pizza Hut', 3002380.5900000036)\n",
      "('Subway', 2998014.270000005)\n",
      "('KFC', 2954233.449999999)\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "cur.execute(\"\"\"\n",
    "SELECT restaurant_name, SUM(quantity*price) AS revenue\n",
    "FROM Orders o, Restaurants r\n",
    "WHERE o.restaurant_id = r.restaurant_id\n",
    "GROUP BY r.restaurant_name\n",
    "ORDER BY revenue DESC\n",
    "LIMIT 3\n",
    "            \"\"\")\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "GDkuTjVB_jex"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Burger King', 'Chinese', 649)\n",
      "('Burger King', 'Continental', 689)\n",
      "('Burger King', 'Dessert', 658)\n",
      "('Burger King', 'Fast Food', 799)\n",
      "('Burger King', 'Italian', 681)\n",
      "('KFC', 'Chinese', 754)\n",
      "('KFC', 'Continental', 757)\n",
      "('KFC', 'Dessert', 641)\n",
      "('KFC', 'Fast Food', 747)\n",
      "('KFC', 'Italian', 735)\n",
      "(\"McDonald's\", 'Chinese', 658)\n",
      "(\"McDonald's\", 'Continental', 665)\n",
      "(\"McDonald's\", 'Dessert', 651)\n",
      "(\"McDonald's\", 'Fast Food', 686)\n",
      "(\"McDonald's\", 'Italian', 699)\n",
      "('Pizza Hut', 'Chinese', 801)\n",
      "('Pizza Hut', 'Continental', 803)\n",
      "('Pizza Hut', 'Dessert', 746)\n",
      "('Pizza Hut', 'Fast Food', 638)\n",
      "('Pizza Hut', 'Italian', 738)\n",
      "('Subway', 'Chinese', 705)\n",
      "('Subway', 'Continental', 730)\n",
      "('Subway', 'Dessert', 715)\n",
      "('Subway', 'Fast Food', 746)\n",
      "('Subway', 'Italian', 859)\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "cur.execute(\"\"\"\n",
    "SELECT restaurant_name, category, SUM(quantity) AS total_quantity\n",
    "FROM Orders o\n",
    "JOIN Restaurants r \n",
    "    ON o.restaurant_id = r.restaurant_id\n",
    "GROUP BY r.restaurant_name, o.category\n",
    "            \"\"\")\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HDkYUWUA_jey"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C3134', 7496.849999999999)\n",
      "('C2515', 7495.05)\n",
      "('C6021', 7494.650000000001)\n",
      "('C2857', 7493.6)\n",
      "('C3320', 7491.799999999999)\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "cur.execute(\"\"\"\n",
    "SELECT c.customer_id,  SUM(quantity*price) AS total_spending\n",
    "FROM Orders o\n",
    "JOIN Customers c\n",
    "    ON o.customer_id = c.customer_id\n",
    "GROUP BY c.customer_id\n",
    "ORDER BY total_spending DESC\n",
    "LIMIT 5\n",
    "            \n",
    "            \"\"\")\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "6WJ59Wag_jey"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"McDonald's\", 3.0026292725679227)\n",
      "('KFC', 2.974673202614379)\n",
      "('Pizza Hut', 2.9493464052287583)\n",
      "('Subway', 3.0873015873015874)\n",
      "('Burger King', 2.9661164205039094)\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "cur.execute(\"\"\"\n",
    "SELECT restaurant_name, AVG(rating)\n",
    "FROM Orders o\n",
    "JOIN Restaurants r \n",
    "    ON o.restaurant_id = r.restaurant_id\n",
    "GROUP BY r.restaurant_id\n",
    "            \"\"\")\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2A86iBk2_jey"
   },
   "outputs": [],
   "source": [
    "#6\n",
    "cur.execute(\"\"\" \n",
    "SELECT customer_id, restaurant_id, order_date, COUNT(*)\n",
    "FROM Orders\n",
    "GROUP BY customer_id, restaurant_id, order_date\n",
    "HAVING COUNT(*)>1\n",
    "\"\"\")\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "S4DVXq5r_jey"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cancelled', 32)\n",
      "('Delayed', 32)\n",
      "('Delivered', 34)\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "cur.execute(\"\"\" \n",
    "SELECT delivery_status, COUNT(*) * 100 / (SELECT COUNT(*) FROM Orders) AS percentage\n",
    "FROM Orders\n",
    "GROUP BY delivery_status\n",
    "\"\"\")\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ZYHl2joP_jey"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Multan', 3052313.7999999975, 21.27950717333175)\n",
      "('Lahore', 2916372.349999998, 20.331777925956168)\n",
      "('Peshawar', 2906686.380000001, 20.26425122929227)\n",
      "('Islamabad', 2835310.270000003, 19.766645627682937)\n",
      "('Karachi', 2633229.2800000007, 18.357818043736938)\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "cur.execute(\"\"\"\n",
    "SELECT c.city, SUM(quantity*price) AS total_revenue, SUM(quantity*price) * 100 / (SELECT SUM(quantity*price) FROM Orders)\n",
    "FROM Orders o\n",
    "JOIN Customers c\n",
    "    ON o.customer_id = c.customer_id\n",
    "GROUP BY city\n",
    "ORDER BY total_revenue DESC        \n",
    "            \"\"\")\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTXBu8Dql0Iv"
   },
   "source": [
    "# PLAGIARISM\n",
    "\n",
    "All work on assignments must be done individually. You are encouraged to discuss the given assignments with your classmates, but these discussions should be carried out in an abstract way. That is, discussions related to a particular solution to a specific probem (either in actual code or in pseudocode) will not be tolerated. In short, turning in someone else’s work (including work available on the internet), in whole or in part, as your own will be considered as a violation of academic integrity. Please note that the former conditions also hold for the material attained using AI tools, including ChatGPT, GitHub Copilot, etc."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
